{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p><font color=deepskyblue>&#9658; Data Mining : Collect Twitter Data into MongoDB &#9664;</font></p>\n",
    "\n",
    "\n",
    "___\n",
    "# <p><font color=teal> &#129414; Instructions </font></p>\n",
    "\n",
    "**We want to be able to extract tweets based on one or several specific hastags from twitter to then analyse them.**\n",
    "\n",
    "To achieve this goal we will go through these steps:\n",
    "\n",
    "- Install **MongoDB**\n",
    "- Get your personal credentals from the **Twitter API**\n",
    "- Select some **hastags** related to an event or movement (/!\\ we will use tweepy stream and you cannot collect tweets older than one week with it, so the event has to be in trends)\n",
    "- Use the Stream API to **collect tweets** to create our dataset (I collected 5000 tweets in another project, I guess 1000 would be a minimum, so it's better when it's a very trendy topic like a political election or an international sports event for instance)\n",
    "- **Analyse** the collected tweets\n",
    "\n",
    "\n",
    "#### Useful sources:\n",
    "* [**Mining the Social Web, 2nd Edition by Matthew A. Russell**](https://www.webpages.uidaho.edu/~stevel/504/Mining-the-Social-Web-2nd-Edition.pdf) (really cool and detailed book for mining Twitter, Facebook, Linkedin, Google+, web pages, etc!)\n",
    "* [twitter doc](https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/post-statuses-filter) the API limits permit you to do the requests inside the boundaries of the API\n",
    "* composition of a [twit object](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)\n",
    "\n",
    "#### Frequent questions:\n",
    "* **Does it work only for hashtags ?** <br>\n",
    "* **Is it legal ?** <br> Yes because tweets are public, it's like doing a RT. The API dosen't give you access to personal users's data. But make sure it respect the RGDP is you do more operations\n",
    "* **What is the limit of tweets that you can collect ?** <br>\n",
    "* **What kind of data do I have access to?** <br>\n",
    "\n",
    "___\n",
    "# <p><font color=teal> &#129414; Set Up </font></p>\n",
    "\n",
    "* Install [pymongo](https://pymongo.readthedocs.io/en/stable/installation.html) ([installation youtube video](https://youtu.be/FwMwO8pXfq0))\n",
    "* check that you have MongoDB Compass\n",
    "* Install [tweepy](http://docs.tweepy.org/en/latest/install.html)\n",
    "* [create a twitter application](https://developer.twitter.com/en/application/intent) on [Twitter API](https://apps.twitter.com/) and get your acess tokens / credentials <br>\n",
    "(TUTORIAL FOR THIS STEP: [Authenticate a Python Application with Twitter using Tweepy](https://www.digitalocean.com/community/tutorials/how-to-authenticate-a-python-application-with-twitter-using-tweepy-on-ubuntu-14-04))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p><font color=lightsteelblue> &#129370; PART 1: Collect the tweets </font></p>\n",
    "### a) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json\n",
    "import pymongo\n",
    "\n",
    "# mongo connection\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Load your personal secret keys\n",
    "\n",
    "You need to create a `.keys.json` file in the root of your folder with your personal access tokens that you got on the [Twitter API](https://apps.twitter.com/) as explained in Set Up:\n",
    "\n",
    "`[{\n",
    "    \"consumer_key\": \"\",\n",
    "    \"consumer_secret\": \"\",\n",
    "    \"access_token\": \"\",\n",
    "    \"access_token_secret\": \"\"\n",
    "}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and load the credentals stored in the file .keys.json\n",
    "''' Assumes a file \".keys.json\" where all credentals are stored as:\n",
    "[{\n",
    "    \"consumer_key\": \"\",\n",
    "    \"consumer_secret\": \"\",\n",
    "    \"access_token\": \"\",\n",
    "    \"access_token_secret\": \"\"\n",
    "}]\n",
    "'''\n",
    "\n",
    "with open('.keys.json', 'r') as myFile:\n",
    "    data = json.load(myFile)\n",
    "\n",
    "consumer_key = data[0]['consumer_key']\n",
    "consumer_secret = data[0]['consumer_secret']\n",
    "access_token = data[0]['access_token']\n",
    "access_token_secret = data[0]['access_token_secret']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Fetch the stream of tweets\n",
    "\n",
    "We will now use **MongoDB** with tweetpy ! What is MongoDB ? <br>\n",
    "MongoDB is a **NoSQL database** (it means that the data isn't stored in tables but in documents. It is useful for projects that need to be developed rapidely when you don't have a full overview and it offers flexibility, so it is less strict). <br>\n",
    "The **documents** are saved into **JSON format**.<br>\n",
    "**Databases** hold one or more collections of documents.<br>\n",
    "MongoDB stores documents in **collections**. Collections are analogous to tables in relational databases.<br>\n",
    "(Learn more in [Mongo DB documentation](https://docs.mongodb.com/manual/core/databases-and-collections/))\n",
    "\n",
    "<img src=\"MongoDBdbcol.png\" align=\"left\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START COLLECTING TWEETS\n",
      "<class 'str'>\n",
      "1\n",
      "<class 'str'>\n",
      "2\n",
      "<class 'str'>\n",
      "3\n",
      "<class 'str'>\n",
      "4\n",
      "<class 'str'>\n",
      "5\n",
      "<class 'str'>\n",
      "6\n",
      "<class 'str'>\n",
      "7\n",
      "<class 'str'>\n",
      "8\n",
      "<class 'str'>\n",
      "9\n",
      "<class 'str'>\n",
      "10\n",
      "--- STOP THE SCRIPT ---\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['analysis'] # your database name // example: client['YOUR_DB_NAME']\n",
    "collection = db['loisecuriteglobale3'] # your collection name // example: db['YOUR_COLLECTION_NAME']\n",
    "count_collectedtweets = 0 # made to keep track of how much tweets you have collected\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\" A listener handles tweets that are received from the stream.\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(type(data))\n",
    "        collection.insert_one(json.loads(data)) # add the collected tweet into the collection\n",
    "        global count_collectedtweets \n",
    "        count_collectedtweets = count_collectedtweets+1\n",
    "        print(count_collectedtweets) # print the number of the collected tweet while collecting\n",
    "        # Fix a limit of tweets to collect (I would say that at least 1000 would be nice)\n",
    "        if count_collectedtweets < 10:\n",
    "            return True #collect\n",
    "        else:\n",
    "            return False #stop\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    stream = Stream(auth, l)\n",
    "    print('START COLLECTING TWEETS')\n",
    "    stream.filter(track=['loisecuriteglobale', 'violencepoliciere','racisme'])\n",
    "    print('--- STOP THE SCRIPT ---')\n",
    "    #example: stream.filter(track=['GJ', 'giletsjaunes', 'greve','macron','retraites']) #results in french\n",
    "    #example: stream.filter(track=['covid19', 'covid', 'corona','confinement','masques']) #results in various languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p><font color=lightsteelblue> &#128035; PART 2: Create a database </font></p>\n",
    "\n",
    "### a) check and import the collection inside a .json file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use MongoDB compass, connect locally, then export your .json file and save it in your root folder\n",
    "\n",
    "Connection string to connect locally: **mongodb://localhost:27017/admin?readPreference=primary&appname=MongoDB%20Compass&ssl=false**\n",
    "\n",
    "\n",
    "<img src=\"MongoDBcompassLocalhost.png\" style=\"width: 500px;\"/>\n",
    "<img src=\"exportcollectioninjson.png\" style=\"width: 500px;\"/>\n",
    "<img src=\"exportcollectioninjson2.png\" style=\"width: 500px;\"/><br>\n",
    "\n",
    "Otherwise you can use the MongoDB prompt:\n",
    "\n",
    "`mongoexport --db YOUR_DB_NAME --collection YOUR_COLLECTION_NAME --out YOUR_COLLECTION_NAME.json`\n",
    "\n",
    "example:`mongoexport --db analysis --collection loisecuriteglobale3 --out loisecuriteglobale3.json`\n",
    "\n",
    "If you already have a collection, you can import it into MongoDB with:\n",
    "\n",
    "`mongoimport -d YOUR_DB_NAME -c brexit  --file YOUR_COLLECTION_NAME.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Display your file\n",
    "\n",
    "Once you saved the .json file in your root folder, you can check it quickly with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '5fd8fb03c807ac4dda964830'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-15 18:05:49</td>\n",
       "      <td>[{'$numberInt': '38'}, {'$numberInt': '140'}]</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'full_text': '@siironique @Raheem0971 @twm1s ...</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>@siironique @Raheem0971 @twm1s @lzylv \"il faut...</td>\n",
       "      <td>2020-12-15 18:05:49.571</td>\n",
       "      <td>True</td>\n",
       "      <td>{'id': {'$numberLong': '1281669801249775617'},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '5fd8fb07c807ac4dda964831'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-15 18:05:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{'url': 'https://t.co/UvLXEm0pTl', 'expanded':...</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Tue Dec 15 17:57:05 +0000 2020...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>RT @Nantes_Revoltee: Nantes ce soir : moment h...</td>\n",
       "      <td>2020-12-15 18:05:53.562</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': {'$numberInt': '271439132'}, 'id_str': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '5fd8fb09c807ac4dda964832'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-15 18:05:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>{'$numberInt': '0'}</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Tue Dec 15 15:45:25 +0000 2020...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @sebastianjroche: Devant la dÃ©nÃ©gation du...</td>\n",
       "      <td>2020-12-15 18:05:55.318</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': {'$numberLong': '717476046900166657'}, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id  contributors  coordinates  \\\n",
       "0  {'$oid': '5fd8fb03c807ac4dda964830'}           NaN          NaN   \n",
       "1  {'$oid': '5fd8fb07c807ac4dda964831'}           NaN          NaN   \n",
       "2  {'$oid': '5fd8fb09c807ac4dda964832'}           NaN          NaN   \n",
       "\n",
       "           created_at                             display_text_range  \\\n",
       "0 2020-12-15 18:05:49  [{'$numberInt': '38'}, {'$numberInt': '140'}]   \n",
       "1 2020-12-15 18:05:53                                            NaN   \n",
       "2 2020-12-15 18:05:55                                            NaN   \n",
       "\n",
       "                                            entities extended_entities  \\\n",
       "0  {'hashtags': [], 'urls': [{'url': 'https://t.c...               NaN   \n",
       "1  {'hashtags': [], 'urls': [], 'user_mentions': ...               NaN   \n",
       "2  {'hashtags': [], 'urls': [], 'user_mentions': ...               NaN   \n",
       "\n",
       "                                      extended_tweet       favorite_count  \\\n",
       "0  {'full_text': '@siironique @Raheem0971 @twm1s ...  {'$numberInt': '0'}   \n",
       "1                                                NaN  {'$numberInt': '0'}   \n",
       "2                                                NaN  {'$numberInt': '0'}   \n",
       "\n",
       "   favorited                        ...                          \\\n",
       "0      False                        ...                           \n",
       "1      False                        ...                           \n",
       "2      False                        ...                           \n",
       "\n",
       "                             quoted_status_permalink          reply_count  \\\n",
       "0                                                NaN  {'$numberInt': '0'}   \n",
       "1  {'url': 'https://t.co/UvLXEm0pTl', 'expanded':...  {'$numberInt': '0'}   \n",
       "2                                                NaN  {'$numberInt': '0'}   \n",
       "\n",
       "         retweet_count  retweeted  \\\n",
       "0  {'$numberInt': '0'}      False   \n",
       "1  {'$numberInt': '0'}      False   \n",
       "2  {'$numberInt': '0'}      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0                                                NaN   \n",
       "1  {'created_at': 'Tue Dec 15 17:57:05 +0000 2020...   \n",
       "2  {'created_at': 'Tue Dec 15 15:45:25 +0000 2020...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                                text            timestamp_ms  \\\n",
       "0  @siironique @Raheem0971 @twm1s @lzylv \"il faut... 2020-12-15 18:05:49.571   \n",
       "1  RT @Nantes_Revoltee: Nantes ce soir : moment h... 2020-12-15 18:05:53.562   \n",
       "2  RT @sebastianjroche: Devant la dÃ©nÃ©gation du... 2020-12-15 18:05:55.318   \n",
       "\n",
       "   truncated                                               user  \n",
       "0       True  {'id': {'$numberLong': '1281669801249775617'},...  \n",
       "1      False  {'id': {'$numberInt': '271439132'}, 'id_str': ...  \n",
       "2      False  {'id': {'$numberLong': '717476046900166657'}, ...  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('loisecuriteglobale3.json', lines=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Format dataframe in a nice way\n",
    "(I reused the code of [hectoramirez](https://github.com/hectoramirez/Language-localization_FIFA) for this part, feel free to modify it to obtain a different formating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# list all files containing tweets\n",
    "files = list(glob.iglob('loisecuriteglobale3.json'))\n",
    "\n",
    "tweets_data = []\n",
    "for file in files:\n",
    "    \n",
    "    tweets_file = open(file, \"r\", encoding = 'utf-8')\n",
    "\n",
    "    # Read in tweets and store in list: tweets_data\n",
    "    for line in tweets_file:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "\n",
    "    tweets_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 tweets in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(tweets_data), 'tweets in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tweets(tweets):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON is \n",
    "        in a top-level dictionary. \"\"\"\n",
    "    \n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet_obj in tweets:\n",
    "    \n",
    "        ''' User info'''\n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "        \n",
    "        # Store the user location\n",
    "        tweet_obj['user-location'] = tweet_obj['user']['location']\n",
    "    \n",
    "        ''' Text info'''\n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = \\\n",
    "                                    tweet_obj['extended_tweet']['full_text']\n",
    "    \n",
    "        if 'retweeted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in \n",
    "            # 'retweeted_status-user-screen_name'\n",
    "            tweet_obj['retweeted_status-user-screen_name'] = \\\n",
    "                        tweet_obj['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['retweeted_status-text'] = \\\n",
    "                                        tweet_obj['retweeted_status']['text']\n",
    "    \n",
    "            if 'extended_tweet' in tweet_obj['retweeted_status']:\n",
    "                # Store the extended retweet text in \n",
    "                #'retweeted_status-extended_tweet-full_text'\n",
    "                tweet_obj['retweeted_status-extended_tweet-full_text'] = \\\n",
    "                tweet_obj['retweeted_status']['extended_tweet']['full_text']\n",
    "                \n",
    "        if 'quoted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in \n",
    "            #'retweeted_status-user-screen_name'\n",
    "            tweet_obj['quoted_status-user-screen_name'] = \\\n",
    "                            tweet_obj['quoted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['quoted_status-text'] = \\\n",
    "                                            tweet_obj['quoted_status']['text']\n",
    "    \n",
    "            if 'extended_tweet' in tweet_obj['quoted_status']:\n",
    "                # Store the extended retweet text in \n",
    "                #'retweeted_status-extended_tweet-full_text'\n",
    "                tweet_obj['quoted_status-extended_tweet-full_text'] = \\\n",
    "                    tweet_obj['quoted_status']['extended_tweet']['full_text']\n",
    "        \n",
    "        ''' Place info'''\n",
    "        if 'place' in tweet_obj:\n",
    "            # Store the country code in 'place-country_code'\n",
    "            try:\n",
    "                tweet_obj['place-country'] = \\\n",
    "                                            tweet_obj['place']['country']\n",
    "                \n",
    "                tweet_obj['place-country_code'] = \\\n",
    "                                            tweet_obj['place']['country_code']\n",
    "                \n",
    "                tweet_obj['location-coordinates'] = \\\n",
    "                            tweet_obj['place']['bounding_box']['coordinates']\n",
    "            except: pass\n",
    "        \n",
    "        tweets_list.append(tweet_obj)\n",
    "        \n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_text(tweets):\n",
    "    ''' Assigns the main text to only one column depending\n",
    "        on whether the tweet is a RT/quote or not'''\n",
    "    \n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet_obj in tweets:\n",
    "        \n",
    "        if 'retweeted_status-extended_tweet-full_text' in tweet_obj:\n",
    "            tweet_obj['text'] = \\\n",
    "                        tweet_obj['retweeted_status-extended_tweet-full_text']\n",
    "        \n",
    "        elif 'retweeted_status-text' in tweet_obj:\n",
    "            tweet_obj['text'] = tweet_obj['retweeted_status-text']\n",
    "            \n",
    "        elif 'extended_tweet-full_text' in tweet_obj:\n",
    "                    tweet_obj['text'] = tweet_obj['extended_tweet-full_text']\n",
    "                \n",
    "        tweets_list.append(tweet_obj)\n",
    "        \n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>user-location</th>\n",
       "      <th>place-country</th>\n",
       "      <th>place-country_code</th>\n",
       "      <th>location-coordinates</th>\n",
       "      <th>user-screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@siironique @Raheem0971 @twm1s @lzylv \"il faut...</td>\n",
       "      <td>fr</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoltan16k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nantes ce soir : moment historique, unique à n...</td>\n",
       "      <td>fr</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cathylabb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devant la dénégation du racisme endémique de l...</td>\n",
       "      <td>fr</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>samb_michele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...</td>\n",
       "      <td>fr</td>\n",
       "      <td>France - Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LeftyMsr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Devant la dénégation du racisme endémique de l...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Paris, Ile-de-France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bien_monsieur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ou j’ai dis mme que le racisme est un truc de ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Rhône-Alpes, France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baabeegurl1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carl_Marois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Devant la dénégation du racisme endémique de l...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Troyes, France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruno__Chatenet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Devant la dénégation du racisme endémique de l...</td>\n",
       "      <td>fr</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nagou_san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...</td>\n",
       "      <td>fr</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tricolore78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang  \\\n",
       "0  @siironique @Raheem0971 @twm1s @lzylv \"il faut...   fr   \n",
       "1  Nantes ce soir : moment historique, unique à n...   fr   \n",
       "2  Devant la dénégation du racisme endémique de l...   fr   \n",
       "3  Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...   fr   \n",
       "4  Devant la dénégation du racisme endémique de l...   fr   \n",
       "5  Ou j’ai dis mme que le racisme est un truc de ...   fr   \n",
       "6  Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...   fr   \n",
       "7  Devant la dénégation du racisme endémique de l...   fr   \n",
       "8  Devant la dénégation du racisme endémique de l...   fr   \n",
       "9  Wallah ! Nique le ! Tue le ! Sale Gwer! ( sale...   fr   \n",
       "\n",
       "          user-location  place-country  place-country_code  \\\n",
       "0                  None            NaN                 NaN   \n",
       "1                FRANCE            NaN                 NaN   \n",
       "2                  None            NaN                 NaN   \n",
       "3        France - Paris            NaN                 NaN   \n",
       "4  Paris, Ile-de-France            NaN                 NaN   \n",
       "5   Rhône-Alpes, France            NaN                 NaN   \n",
       "6                 Paris            NaN                 NaN   \n",
       "7        Troyes, France            NaN                 NaN   \n",
       "8                  None            NaN                 NaN   \n",
       "9                  None            NaN                 NaN   \n",
       "\n",
       "   location-coordinates user-screen_name  \n",
       "0                   NaN        zoltan16k  \n",
       "1                   NaN        Cathylabb  \n",
       "2                   NaN     samb_michele  \n",
       "3                   NaN         LeftyMsr  \n",
       "4                   NaN    Bien_monsieur  \n",
       "5                   NaN      baabeegurl1  \n",
       "6                   NaN      Carl_Marois  \n",
       "7                   NaN  Bruno__Chatenet  \n",
       "8                   NaN        nagou_san  \n",
       "9                   NaN      tricolore78  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten tweets\n",
    "tweets = flatten_tweets(tweets_data)\n",
    "\n",
    "# select text\n",
    "tweets = select_text(tweets)\n",
    "columns = ['text', 'lang', 'user-location', 'place-country', \n",
    "           'place-country_code', 'location-coordinates', \n",
    "           'user-screen_name']\n",
    "\n",
    "# Create a DataFrame from `tweets`\n",
    "df_tweets = pd.DataFrame(tweets, columns=columns)\n",
    "# replaces NaNs by Nones\n",
    "#df_tweets.where(pd.notnull(df_tweets), None, inplace=True)\n",
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      "text                    100 non-null object\n",
      "lang                    100 non-null object\n",
      "user-location           54 non-null object\n",
      "place-country           0 non-null float64\n",
      "place-country_code      0 non-null float64\n",
      "location-coordinates    0 non-null float64\n",
      "user-screen_name        100 non-null object\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 5.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for quick check\n",
    "df_tweets_sample = df_tweets.copy()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p><font color=lightsteelblue> &#128036; PART 3: Tweets analysis </font></p>\n",
    "\n",
    "In this analysis, we decide to extract different informations from the tweets we collected:\n",
    "* popularity of the search interest (defined by you)\n",
    "* top 20 of the hashtags used in the collected tweets\n",
    "* Original content VS Retweet\n",
    "* Number of likes for the collected tweets\n",
    "* Type of content (text, photo, video)\n",
    "\n",
    "Depending of what you want to analyse, you can make these queries very. For instance if you look for information of an international event, you might want to extract and sort counrty data.\n",
    "<br><br><br>\n",
    "\n",
    "<p><font color=indianred>REQUIREMENT</font></p>\n",
    "\n",
    "For the next step, you need to have the **mongod server running** (probably here: `MongoDB\\Server\\version\\bin\\mongod.exe`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pymongo\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# To import the collection to mongoDB:\n",
    "# mongoimport -d analysis -c brexit  --file brexit.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['analysis']\n",
    "collection = db['loisecuriteglobale3']\n",
    "\n",
    "\n",
    "YOUR_SEARCH_INTEREST = \"Loi Securite Globale\"\n",
    "SEARCH_INTEREST = re.compile('stoploisecuriteglobale|loisecuriteglobale|pplsecuriteglobale')\n",
    "\n",
    "outfile = open('tweets_analysis_output_file.txt', 'w')\n",
    "outfile.write('''\n",
    "    ###############\n",
    "    TWEETS ANALYSIS\n",
    "    ###############\n",
    "    ''')\n",
    "\n",
    "def find_popularity():\n",
    "    # ----------------------\n",
    "    # Mentions of __YOUR_SEARCH_INTEREST__ : x\n",
    "    # Total tweets:  xxxx\n",
    "    # -----------------------\n",
    "    outfile.write(\"\\nMENTIONS OF \" + YOUR_SEARCH_INTEREST + \":\\n--------------\")\n",
    "    occurence_of_search_interest = 0\n",
    "    # db_max = \n",
    "    # db_min = \n",
    "    total_valid = 0\n",
    "\n",
    "    cursor = collection.find({})\n",
    "    for doc in cursor:\n",
    "        # db_min += 1\n",
    "        # if db_min < db_max:\n",
    "        try:\n",
    "            text = doc['text']\n",
    "            total_valid += 1\n",
    "        except KeyError:\n",
    "            # print doc['_id']\n",
    "            pass\n",
    "        # print text\n",
    "        occurence_of_search_interest += len(SEARCH_INTEREST.findall(text.lower()))\n",
    "        # else:\n",
    "        #     break\n",
    "    outfile.write(\"\\nMentions of \" + YOUR_SEARCH_INTEREST + \" : \" + str(occurence_of_search_interest))\n",
    "    outfile.write(\"\\nTotal tweets: \" + str(total_valid))\n",
    "    outfile.write('\\n')\n",
    "    outfile.write('\\n')\n",
    "\n",
    "\n",
    "def top_20_hashtags():\n",
    "    # -------------------\n",
    "    # count hashtag\n",
    "    # -------------------\n",
    "    outfile.write(\"\\nTOP 20 HASHTAGS:\\n--------------\\n\")\n",
    "    '''\n",
    "    Traverse through all hashtags in every tweet\n",
    "    - hashtags are present in the attribute - entities.hashtags\n",
    "    - return value - array of hashtags, empty is no hashtag\n",
    "        {\"indices\":[x,y], \"text\": <hashtag-text-here>}\n",
    "\n",
    "    To generate word cloud: https://www.wordclouds.com/\n",
    "    '''\n",
    "    cursor = collection.find({})\n",
    "    # db_max = 10\n",
    "    # db_min = 0\n",
    "    hashtag_counter = Counter()\n",
    "    for doc in cursor:\n",
    "        # db_min += 1\n",
    "        # if db_min < db_max:\n",
    "        try:\n",
    "            hashtag_list = doc['entities']['hashtags']\n",
    "            if len(hashtag_list) > 0:\n",
    "                for ht in hashtag_list:\n",
    "                    hashtag_counter[ht['text'].lower()] += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "        # else:\n",
    "            # break\n",
    "    top_20 = hashtag_counter.most_common(20)\n",
    "\n",
    "    for word, count in top_20:\n",
    "        outfile.write(word + \": \" + str(count) + \"\\n\")\n",
    "    outfile.write(\"\\nTotal number of hashtags used: \" + str(sum(hashtag_counter.values())) + \"\\n\")\n",
    "    outfile.write('\\n')\n",
    "\n",
    "\n",
    "def original_vs_retweeted():\n",
    "\n",
    "    outfile.write(\"\\nTYPES OF TWEETS - ORIGINAL VS RETWEETED:\\n--------------\")\n",
    "    # Original tweets don't have the attribute\n",
    "    #   retweeted_status\n",
    "    # Original\n",
    "    # db.getCollection('loisecuriteglobale3').find({\"retweeted_status\":{$eq:null}},{}).length()\n",
    "    res = collection.count_documents({\"retweeted_status\":{'$eq':None}},{})\n",
    "    outfile.write(\"\\nNumber of original tweets: \" + str(res))\n",
    "    # Retweeted\n",
    "    # db.getCollection('loisecuriteglobale3').find({\"retweeted_status\":{$ne:null}},{}).length()\n",
    "    res = collection.count_documents({\"retweeted_status\":{'$ne':None}},{})\n",
    "    outfile.write(\"\\nNumber of retweeted tweets: \" + str(res))\n",
    "    outfile.write('\\n')\n",
    "    outfile.write('\\n')\n",
    "\n",
    "def fav_counts():\n",
    "    # find no of tweets greater than a number - ex: 50,000 => Outputs: 3\n",
    "    # raw mongo query\n",
    "    # db.getCollection('brexit').find({'retweeted_status.favorite_count':{$gt:30000}}).length()\n",
    "    outfile.write(\"\\nCOUNTS LIKES ON TWEETS:\\n--------------\")\n",
    "    times = [1, 100, 1000, 5000, 10000, 50000]\n",
    "    for value in times:\n",
    "        res = collection.count_documents({'retweeted_status.favorite_count':{'$gt':value}})\n",
    "        outfile.write(\"\\nNumber of tweets favorited more than \" + str(value) + \" times: \" + str(res))\n",
    "    outfile.write('\\n')\n",
    "    outfile.write('\\n')\n",
    "\n",
    "def tweet_type():\n",
    "\n",
    "    outfile.write(\"\\nTYPES OF TWEET CONTENT - TEXT / AUDIO / VIDEO\\n--------------\")\n",
    "    # only text: 4822\n",
    "    # db.getCollection('loisecuriteglobale3').find({'entities.media.type':{$eq:null}}).length()\n",
    "    res = collection.count_documents({'entities.media.type':{'$eq':None}})\n",
    "    outfile.write('\\nTweets with only text: ' + str(res))\n",
    "    # ----\n",
    "    # contains Photo: 178\n",
    "    # db.getCollection('loisecuriteglobale3').find({'extended_entities.media.type':'photo'}).length()\n",
    "    res = collection.count_documents({'extended_entities.media.type':'photo'})\n",
    "    outfile.write('\\nTweets with images: ' + str(res))\n",
    "    # ----\n",
    "    # contains Video: 19\n",
    "    # db.getCollection('loisecuriteglobale3').find({'extended_entities.media.type':'video'}).length()\n",
    "    res = collection.count_documents({'extended_entities.media.type':'video'})\n",
    "    outfile.write('\\nTweets with videos: ' + str(res))\n",
    "    # ----\n",
    "    outfile.write('')\n",
    "\n",
    "\n",
    "def main():\n",
    "    find_popularity()\n",
    "    top_20_hashtags()\n",
    "    original_vs_retweeted()\n",
    "    fav_counts()\n",
    "    tweet_type()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ###############\n",
      "    TWEETS ANALYSIS\n",
      "    ###############\n",
      "    \n",
      "MENTIONS OF Loi Securite Globale:\n",
      "--------------\n",
      "Mentions of Loi Securite Globale : 7\n",
      "Total tweets: 110\n",
      "\n",
      "\n",
      "TOP 20 HASHTAGS:\n",
      "--------------\n",
      "nantes: 4\n",
      "loisecuriteglobale: 4\n",
      "marchedeslibertés: 4\n",
      "stoploisecuriteglobale: 3\n",
      "france: 1\n",
      "macron: 1\n",
      "polqc: 1\n",
      "\n",
      "Total number of hashtags used: 18\n",
      "\n",
      "\n",
      "TYPES OF TWEETS - ORIGINAL VS RETWEETED:\n",
      "--------------\n",
      "Number of original tweets: 29\n",
      "Number of retweeted tweets: 81\n",
      "\n",
      "\n",
      "COUNTS LIKES ON TWEETS:\n",
      "--------------\n",
      "Number of tweets liked more than 1 times: 75\n",
      "Number of tweets liked more than 100 times: 51\n",
      "Number of tweets liked more than 1000 times: 10\n",
      "Number of tweets liked more than 5000 times: 1\n",
      "Number of tweets liked more than 10000 times: 0\n",
      "Number of tweets liked more than 50000 times: 0\n",
      "\n",
      "\n",
      "TYPES OF TWEET CONTENT - TEXT / AUDIO / VIDEO\n",
      "--------------\n",
      "Tweets with only text: 104\n",
      "Tweets with images: 6\n",
      "Tweets with videos: 0\n"
     ]
    }
   ],
   "source": [
    "f = open('tweets_analysis_output_file.txt', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p><font color=lightsteelblue> &#129413; PART 4: Data visualisation </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
